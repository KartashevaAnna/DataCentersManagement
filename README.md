# DataCentersManagement

## Описание

Проект собирает отчеты о погоде в 50 крупнейших городах мира.
Отчет содержит название города и температуру, как указано в ТЗ, 
а также данные о давлении, влажности, скорости ветра и порывах ветра, так как это может влиять на дата-центры.
Коллектор собирает данные каждый час, начиная с запуска приложения.


## Технологии

- Python 3.11
- FastAPI
- Pydantic
- SQLAlchemy
- Pandas
- SQLite3
- Docker

## Как развернуть проект

- Клонируйте репозиторий с GitHub
- В корневой директории откройте файл .env
- В переменной ENWEATHERAPIKEY укажите Ваш API ключ от OpenWeatherMap
- Запустите докер 
- Соберите образ и запустите контейнер: ``` docker-compose up -d ```
- Проверить, что сервис поднялся, можно по адресу http://localhost:8008/ping (должен вернуться ответ pong)
- Перейдите на http://localhost:8008/docs
- Для Вашего удобства создан эндпойнт /weather, который возвращает содержимое базы данных.

## Почему такая структура базы данных

Выбрана самая простая из возможных структур, так как ТЗ требует хранить только данные о погоде, для хранения которых достаточно одной таблицы с несколькими полями.

## Почему я выбрала эти технологии

Выбор был между Django, Django Rest и FastAPI (указано в вашей вакансии).
### Почему FastAPI: 

- Имеет смысл в будущем сделать приложение асинхронным, следовательно, Django не подходит
- Имеются требования о легкой поддержке и возможных расширениях функционала. С моей точки зрения, FastAPI в этом плане предлагает больше возможностей.
- FastAPI позволяет развернуть минимальную рабочую версию только с самым необходимым, тогда как DRF тянет за собой большое количество встроенных функций,
которые на данном этапе совершенно не нужны
- По моим ощущениям, DRF сложнее дорабатывать, кастомизировать и расширять
- Получить опыт с FastAPI лично для меня полезнее, чем написать очередное приложение на Django или DRF. Есть желание извлекать пользу и из тестовых заданий тоже

### Выбор базы данных

Рассматривала PostgreSQL и SQLite3. PostgreSQL подошла бы больше для полноценного проекта, тем более что она указана у вас в вакансии.
Однако, чтобы сэкономить свое время, упростить разработку и развертывание, выбрала SQLite3, которой вполне хватает для текущих функций.

### Выбор ORM

Лично мне было бы интересно использовать Tortoise ORM, которую я бы и применила, если бы делала полноценное приложение с полноценной базой данных и асинхронными запросами.
Для минимальной рабочей версии взяла SQLAlchemy в силу понятной документации и возможности прийти к асинхронности, если это потребуется.
Кроме того, был интерес с ней разобраться, так как раньше я с ней не работала.

Я использовала Pydantic для валидации данных. Здесь в этом не было особой нужды, но это пригодится, если приложение будет расширяться.

Также применила Pandas, чтобы показать, что умею с ней работать, так как у вас в вакансии указана обработка данных.

Было сильное желание использовать Podman для контейнера, чтобы сэкономить ресурсы, но в ТЗ четко указан docker-compose.



## Технические ограничения и возможности для улучшения

В проекте я использовала некоммерческий API ключ. Этого достаточно для учебного проекта. 
Для реального применения потребуется коммерческий ключ.

Нужно поменять базу данных на PostgreSQL, возможно, c асинхронной ORM.

Модель создана в самом базовом виде. В зависимости от требований может потребоваться ее расширить или создать несколько сущностей.
Как минимум, видится полезным хранить еще и timestamps. Возможно, вынести города в отдельную сущность, если эти данные потом 
нужно будет каким-то образом компоновать или анализировать.

Можно будет указать volumes в docker-compose, чтобы сохранять данные из базы данных в случае удаления контейнера.

Стоит подключить логирование.

Нужно написать тесты.

Нужно обрабатывать исключения.
